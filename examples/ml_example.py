"""
Exemplo de Pipeline de Machine Learning usando Books API
Demonstra como usar a API para treinar modelos
"""
import requests
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
import warnings

warnings.filterwarnings('ignore')


class BooksMLPipeline:
    """Pipeline de ML para Books API"""
    
    def __init__(self, api_url: str = "http://localhost:8000"):
        self.api_url = api_url
        self.df = None
        self.label_encoder = LabelEncoder()
        
    def load_data(self, size: int = 800, random_state: int = 42):
        """Carrega dados da API"""
        print(f"üì• Carregando {size} livros da API...")
        
        response = requests.get(
            f"{self.api_url}/ml/sample",
            params={"size": size, "random_state": random_state}
        )
        response.raise_for_status()
        
        data = response.json()
        self.df = pd.DataFrame(data['data'])
        
        print(f"‚úÖ Carregados {len(self.df)} livros")
        print(f"üìä Features: {list(self.df.columns)}")
        return self.df
    
    def preprocess_data(self):
        """Pr√©-processamento dos dados"""
        print("\nüîß Pr√©-processamento...")
        
        # Encode categoria
        self.df['category_encoded'] = self.label_encoder.fit_transform(self.df['category'])
        
        # Criar features adicionais
        self.df['title_length'] = self.df['title'].str.len()
        self.df['desc_length'] = self.df['description'].str.len()
        self.df['has_long_desc'] = (self.df['desc_length'] > 100).astype(int)
        
        print(f"‚úÖ Features criadas: category_encoded, title_length, desc_length, has_long_desc")
        
    def train_price_predictor(self):
        """Treina modelo para prever pre√ßos"""
        print("\n" + "=" * 80)
        print("üí∞ MODELO 1: Predi√ß√£o de Pre√ßos")
        print("=" * 80)
        
        # Features e target
        X = self.df[[
            'category_encoded',
            'rating',
            'availability_copies',
            'title_length',
            'desc_length',
            'has_long_desc'
        ]]
        y = self.df['price']
        
        # Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        print(f"\nüìä Dataset:")
        print(f"  - Treino: {len(X_train)} amostras")
        print(f"  - Teste: {len(X_test)} amostras")
        
        # Treinar
        model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        
        print(f"\nüèãÔ∏è  Treinando Random Forest Regressor...")
        model.fit(X_train, y_train)
        
        # Avaliar
        y_pred = model.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        
        print(f"\nüìà Resultados:")
        print(f"  - RMSE: ¬£{rmse:.2f}")
        print(f"  - R¬≤ Score: {r2:.4f}")
        print(f"  - MAE: ¬£{np.mean(np.abs(y_test - y_pred)):.2f}")
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nüéØ Feature Importance:")
        for _, row in feature_importance.iterrows():
            bar = "‚ñà" * int(row['importance'] * 100)
            print(f"  {row['feature']:20s} {bar} {row['importance']:.4f}")
        
        # Exemplos de predi√ß√£o
        print(f"\nüîÆ Exemplos de Predi√ß√£o:")
        for i in range(min(5, len(X_test))):
            real = y_test.iloc[i]
            pred = y_pred[i]
            diff = abs(real - pred)
            print(f"  Real: ¬£{real:.2f} | Predito: ¬£{pred:.2f} | Diff: ¬£{diff:.2f}")
        
        return model
    
    def train_rating_classifier(self):
        """Treina modelo para classificar ratings"""
        print("\n" + "=" * 80)
        print("‚≠ê MODELO 2: Classifica√ß√£o de Ratings")
        print("=" * 80)
        
        # Features e target
        X = self.df[[
            'price',
            'category_encoded',
            'availability_copies',
            'title_length',
            'desc_length'
        ]]
        y = self.df['rating']
        
        # Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"\nüìä Dataset:")
        print(f"  - Treino: {len(X_train)} amostras")
        print(f"  - Teste: {len(X_test)} amostras")
        
        # Treinar
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        
        print(f"\nüèãÔ∏è  Treinando Random Forest Classifier...")
        model.fit(X_train, y_train)
        
        # Avaliar
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nüìà Resultados:")
        print(f"  - Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        # Classification report
        print(f"\nüìä Classification Report:")
        print(classification_report(y_test, y_pred, target_names=[f"{i} ‚≠ê" for i in range(1, 6)]))
        
        # Cross-validation
        cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
        print(f"\nüîÑ Cross-Validation (5-fold):")
        print(f"  - Scores: {[f'{s:.4f}' for s in cv_scores]}")
        print(f"  - Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
        
        return model
    
    def analyze_correlations(self):
        """Analisa correla√ß√µes entre vari√°veis"""
        print("\n" + "=" * 80)
        print("üî¨ AN√ÅLISE DE CORRELA√á√ïES")
        print("=" * 80)
        
        # Correla√ß√µes com pre√ßo
        price_corr = self.df[[
            'price', 'rating', 'availability_copies',
            'title_length', 'desc_length', 'category_encoded'
        ]].corr()['price'].sort_values(ascending=False)
        
        print(f"\nüí∞ Correla√ß√£o com Pre√ßo:")
        for feature, corr in price_corr.items():
            if feature != 'price':
                emoji = "üìà" if corr > 0 else "üìâ"
                bar = "‚ñà" * int(abs(corr) * 20)
                print(f"  {emoji} {feature:25s} {bar} {corr:+.4f}")
        
        # Correla√ß√µes com rating
        rating_corr = self.df[[
            'rating', 'price', 'availability_copies',
            'title_length', 'desc_length', 'category_encoded'
        ]].corr()['rating'].sort_values(ascending=False)
        
        print(f"\n‚≠ê Correla√ß√£o com Rating:")
        for feature, corr in rating_corr.items():
            if feature != 'rating':
                emoji = "üìà" if corr > 0 else "üìâ"
                bar = "‚ñà" * int(abs(corr) * 20)
                print(f"  {emoji} {feature:25s} {bar} {corr:+.4f}")
    
    def generate_insights(self):
        """Gera insights dos dados"""
        print("\n" + "=" * 80)
        print("üí° INSIGHTS")
        print("=" * 80)
        
        # Estat√≠sticas por categoria
        print(f"\nüìö Top 5 Categorias por Pre√ßo M√©dio:")
        cat_stats = self.df.groupby('category')['price'].agg(['mean', 'count']).sort_values('mean', ascending=False)
        for cat, row in cat_stats.head().iterrows():
            print(f"  {cat:30s} ¬£{row['mean']:6.2f} ({int(row['count'])} livros)")
        
        # Rating vs Pre√ßo
        print(f"\n‚≠ê Pre√ßo M√©dio por Rating:")
        rating_price = self.df.groupby('rating')['price'].mean().sort_index()
        for rating, price in rating_price.items():
            stars = "‚≠ê" * rating
            print(f"  {stars:15s} ¬£{price:.2f}")
        
        # Disponibilidade
        print(f"\nüì¶ Disponibilidade:")
        avail_stats = self.df['availability'].value_counts()
        for status, count in avail_stats.items():
            pct = (count / len(self.df)) * 100
            bar = "‚ñà" * int(pct / 2)
            print(f"  {status:20s} {bar} {count} ({pct:.1f}%)")


def main():
    """Fun√ß√£o principal"""
    print("\n")
    print("‚ïî" + "=" * 78 + "‚ïó")
    print("‚ïë" + " " * 15 + "ü§ñ BOOKS API - MACHINE LEARNING PIPELINE" + " " * 22 + "‚ïë")
    print("‚ïö" + "=" * 78 + "‚ïù")
    
    try:
        # Criar pipeline
        pipeline = BooksMLPipeline()
        
        # Carregar e preparar dados
        pipeline.load_data(size=800)
        pipeline.preprocess_data()
        
        # An√°lises
        pipeline.analyze_correlations()
        pipeline.generate_insights()
        
        # Treinar modelos
        model_price = pipeline.train_price_predictor()
        model_rating = pipeline.train_rating_classifier()
        
        # Conclus√£o
        print("\n" + "=" * 80)
        print("‚úÖ Pipeline de ML conclu√≠do com sucesso!")
        print("=" * 80)
        
        print("\nüí° Pr√≥ximos Passos:")
        print("  1. Salvar modelos treinados (pickle/joblib)")
        print("  2. Implementar endpoint POST /ml/predict na API")
        print("  3. Deploy dos modelos em produ√ß√£o")
        print("  4. Monitorar performance dos modelos")
        print("  5. Re-treinar periodicamente com novos dados")
        
        print("\nüìö Casos de Uso:")
        print("  - Sistema de recomenda√ß√£o de pre√ßos")
        print("  - Predi√ß√£o de popularidade (rating)")
        print("  - Detec√ß√£o de anomalias em pre√ßos")
        print("  - Segmenta√ß√£o de livros (clustering)")
        print("  - An√°lise de sentimento em descri√ß√µes")
        
        print("\n" + "=" * 80 + "\n")
        
    except requests.exceptions.ConnectionError:
        print("\n‚ùå ERRO: N√£o foi poss√≠vel conectar √† API")
        print("   Certifique-se de que a API est√° rodando:")
        print("   uvicorn api.main:app --reload")
    except Exception as e:
        print(f"\n‚ùå ERRO: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

